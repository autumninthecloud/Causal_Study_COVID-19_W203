---
title: "Section_8_Team1_Lab2_Report"
author: "Degnan, Rains, Wu"
date: "8/1/2021"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r setup, message=FALSE}
install.packages("table1")
install.packages("GGally")
install.packages("stargazer")

#we may not need all of these
library(tidyverse)
library(magrittr)
library(ggplot2)
library(patchwork)
library(sandwich)
library(lmtest)
library(dplyr)
library(table1)
library(GGally)
library(stargazer)
theme_set(theme_minimal())
knitr::opts_chunk$set(echo = TRUE)

```

## Introduction

Summer vacations in the United States are synonymous with sunny, leisurely days spent with loved ones. As Ella Fitzgerald so aptly sings, “Summertime, and the living is easy.” However, travel in the recent peak-vacation months has certainly deviated from this idealistic frame of mind with the onset of the COVID-19 pandemic in early 2020. The global travel industry has experienced sharp declines. Specifically in the United States, “travel spending totaled a mere $679 billion in 2020, an unprecedented 42% annual decline (nearly $500 billion) from 2019,” according to analysis from the U.S. Travel Association. 
As infection and vaccination rates oscillate regionally along with government policies for business operation restrictions in the United States, our team of data scientists will look to answer the following research question in more detail using linear regression techniques: 

Do COVID infection rates impact vacation travel distance for U.S. residents in the state of Texas? 
How does income, population density, and covid regulations in each county impact traveling? 

We will analyze datasets pertaining to these variables for Texas counties and create three models to understand if causal relationships exist between distance traveled, population income, population density (rural or urban counties), and government regulations. Our hypothesis is that an there is a causal relationship between """

## Operationalization

To create our dataframe, we cleaned and filtered data from multiple sources of data and joined based on texas county name or code. 

#### Operationalization of focus variables
We gathered covid case and death data from NYT. We gathered trip distance data from the Bureau of Transportation, which they record based on data gathered from personal mobile devices. This data was presented as number of travelers in binned distances. We defined a short trip as less than 100 miles and long trips as greater than 100 miles. This was decided under the assumption that distances traveled of less than 100 miles are for the purpose of commuting, while greater than 100 miles indicated vacation travel. Hand in hand with this variable is our indicator variable for urban vs rural setting *** how did we decide this again, population threshold?**** under the assumption that those who live in rural settings are likely to commute further than those in an urban setting. Finally, we believe that median household income plays a significant role in an individual's ability to take vacations. We pulled this directly from the US Census Bureau. 

#### Operationalization of additional variables
To enrich our model and limit OVB, we brainstormed a number of additional variables that could affect travel rates during covid. For one, we looked at how covid affected the county, through the unemployment rate. We also looked at age, gender, income demographics. Then, in addition to income demographics, we focused on percent of younger folks, as defined as those younger than 17 and older folks as defined as those older than 65 because of the nature of how covid affects an individual.


### Variables

For our analysis, we will use datasets and variables from the four following sources:

[![DataSources](lab2datatable.JPG)](https://ibb.co/zQ3yj2K)

As indicated, each source will provide information on county population demographics such as income, rural vs. urban classification, and status of pandemic regulations. Together, these sources were filtered for the state of Texas and combined to create a dataframe for analysis.

```{r dataframe, echo=FALSE}
df <- read.csv('~/lab-2-lab2_section8_jal/data/interim/covid_trips_interim_model3.csv')
#head(df)
```

## Exploratory Data Analysis

Table 1 below displays some information about the mean, median, minimum and maximum values for each variable. Figure 1 below depicts the distribution and correlation of each variable in our dataset by county type (where '0' indicates an urban county). From Figure 1, it can be observed that some of the variables are not distributed normally, are skewed,  and thus require transformations. More specifically, these variables are: Total Population, Total Cases, Total Deaths, Population Density. The outcome variable, Long Distance, will also require transformation. Upon further analysis, logarithmic transformations were chosen to normalize the distribution and minimize skewness. 

```{r EDA}
#Example Table
df$rural_cat <- ifelse(df$is_rural == 1, "Rural Counties", "Urban Counties")
table1::label(df$total_pop) <- "County Population"
table1::label(df$density) <- "County Population Density"
table1::label(df$cases) <- "County Covid-19 Cases"
table1::label(df$unempoy_rate) <- "County Unemployment Rate"
table1::label(df$median_income) <- "County Median Income ($)"
table1::label(df$pct_lt17) <- "County Age < 17 years (%)"
table1::label(df$pct_gt65) <- "County Age > 65 years (%)"
# table1::label(df$is_rural) <- "County Type"
table1::table1(~total_pop + density + cases + unempoy_rate + median_income + pct_lt17 + pct_gt65 | rural_cat, data = df, caption = "Table 1: Texas County Variable Statistics", topclass="Rtable1-zebra", overall = "Total")

#Short vs long trip: rate of short trips is higher than rate of long trips in relation to # of covid cases
ggplot(data = df) + aes(x = log(cases), y = log(long_trip)) + geom_point()
#ggplot(data = df) + aes(x = log(cases), y = log(short_trip)) + geom_point()

Rural_County=as.factor(df$is_rural)

df %>% 
  mutate(
    total_pop = log(total_pop),
    cases = log(cases+1),
    deaths = log(deaths+1),
    long_trip = log(long_trip),
    density = log(density)
  ) %>%
  select(long_trip, cases, deaths, median_income, unempoy_rate, density, pct_lt17) %>% 
  GGally::ggpairs(.,
               legend = 1, title = "Figure 1: Variable Statistics",
               mapping = ggplot2::aes(colour=Rural_County))

```


### Accounting Tables

To demonstrate the operationalization of the data, Tables 1 and 2 below display the original value counts from the dataset as well as how many values were removed as a part of filtering the dataset to remove all states except Texas. For the analysis, 230 responses were analyzed as shown in Table 1. Table 2 depicts the county type breakdown for rural or urban classification as well. 

```{r Accounting Table creation & output}

df2 <- df

df2$log_pop <- log10(df2$total_pop+1)
df2$log_cases <-log10(df2$cases+1)
df2$log_deaths <-log10(df2$deaths+1)
df2$log_long_trip <-log10(df2$long_trip+1)
df2$log_density <- log10(df2$density+1)

#summary(df2)
df2 <- df2 %>% filter(!is.na(df2))
#df2 <- df2 %>% filter(!is.infinite(df2))

step_num = c(1,2)

number_of_samples = c(nrow(df),
                      nrow(df2))
samples_removed = c(0,
                    nrow(df)-nrow(df2))

                    
reasoning = c("Original Dataset",
              "Logarithmic Transformations")

accounting_df <- data.frame(step_num,
                            number_of_samples,
                            samples_removed,
                            reasoning)

#knitr::kable(accounting_df)
colnames(accounting_df) <- c('Step','Number of Samples','Samples Removed', 'Reason')
knitr::kable(accounting_df, caption="Accounting Table", align = "c")

final_tab_df = dplyr::count(df2, rural_cat, sort = TRUE)
colnames(final_tab_df) <- c('County Type', 'Number of Samples')
knitr::kable(final_tab_df, caption="Table 2: Final Samples by County Type", align = "c")
```


#### Additional Changes to the Data:

Upon final review of the dataset, there are no additional changes required to prepare the dataset for data exploration and subsequent model creation. Outliers or incorrect data are not observed upon final inspection. The Accounting Table capture the changes made through cleaning and filtering as indicated previously. Table 2 above also displays the subset per county type for the overall dataset.

## A Model Building Process

## Linear Regression Results

```{r model creation, warning=FALSE}

#need to change these to per capita data
model1 <- lm(log(long_trip+1) ~ log(cases+1) + log(deaths+1) + is_rural + median_income, data = df) #limited model
model2 <- lm(log(long_trip+1) ~ log(cases+1) + log(deaths+1) + is_rural + median_income + unempoy_rate + log(density+1), data = df)
model3 <- lm(log(long_trip+1) ~ log(cases+1) + log(deaths+1) + is_rural + median_income + unempoy_rate + log(density+1) + pct_lt17, data = df) #final model

stargazer(model1, model2, model3, type='text', title="Results", align=TRUE)


#Run F test to show statistical significance of additional variables
anova(model1, model2, test = "F")
anova(model2, model3, test = "F")

#Run coeftest to show statistical significance of all variables in the model
coeftest(model3, vcov = vcovHC(model3, type="HC1"))
```

## Discussion
### Model Limitations

1. **IID Sampling:** There isn't a direct database check for this unfortunately. Looking into how this data was generated, I belive this is IID generally. The data was gathered from independent YouTube uploaders and was a random sample.
2. **No Perfect Colinearity:** Running a VIF in R in the cell below, we see the VIF score is relatively low for both predictors. Conceptually, we can see no perfect colinearity as we cannot perfectly describe the views variable in terms of average rating or vice versa. Additionally, from the last scatter plot above, we don't see a perfect linear relationship between the predictor variabls views or average rating.
3. **Linear Conditional Expectation:** 'For this assumption, we are checking the residuals for linear relationships. We can view this by plotting the residuals, as seen below. We generally see a linear line as we move across predictor values with the residuals with no strong pattern. By transforming the average rating and views (log of), we are able to see this linear relationship across all predictor values. 
4. **Homoskedastic Errors:** 'We are looking for constant error variance across the entire range of the x's ( homoskedastic errors across the range of the x's). From the residual plot below for the final model ('Final Model' figure), we can see the even or equal spread dispersion across the x values whereas with the other two models, this is not as consistent. The residual plots for the other two show increases with the value of the fitted  variables, suggesting non-constant variances in the residuals errors (or heteroscedasticity). Therefore our final model does meet this condition.  We are able to achieve this fianl plot through transfomrtion of views and average rating (log).
5. **Normally Distributed Errors:** We are looking for a normal distribution of the residuals. We use the QQ plot to investigate this assumption. For the final model, we see a nice linear line from the QQ plot whereas the other two previou models do not show this. We are able to achieve this fianl plot through transfomrtion of views and average rating (log). In conclusion, we meet this assumption with the final model ("Final Model" plot, model = model_transformviewsrating).

```{r CLM assumptions check}

#run this to display the CLM graphs needed to verify CLM assumptions met
par(mfrow = c(2, 2))
plot(model2, col="blue") 
title("Model 2", line = -0.75, outer = TRUE)

##FINAL MODEL
par(mfrow = c(2, 2))
plot(model3, col="red") 
title("Model 2", line = -0.75, outer = TRUE)

```

###Omitted Variable 

<!-- If the team has taken up an explanatory (i.e. causal) question to evaluate, then identify what you think are the most important omitted variables that bias results you care about. For each variable you name, you should reason about the direction of bias caused by omitting this variable. If you can argue whether the bias is large or small, that is even better. State whether you have any variables available that may proxy (even imperfectly) for the omitted variable. Pay particular attention to whether each omitted variable bias is towards zero or away from zero. You will use this information to judge whether the effects you find are likely to be real, or whether they might be entirely an artifact of omitted variable bias. -->

#### Variable 1

One example of an omitted variable that may cause bias in our model is that of vehicle ownership among the population. It can certainly be expected that individuals that own a vehicle would be able to more easily travel short or long distances more frequently with relative ease. If an individual owned a vehicle, this would influence our model by driving the bias further from zero. From the data available, there would no immediate proxy for this omitted variable.

#### Variable 2

Another example of an omitted variable that may also cause bias in our model is fuel prices. Whether this is jet fuel or gasoline, fluctuations in this commodity would certainly impact travel costs. If fuel prices increase, it is generally observed that costs for travel increase. The opposite is also generally true. In the instance of increased fuel prices, this would influence our model by driving the bias closer to zero as distance traveled would drop. Conversely, if fuel prices for the time period of the sample for the population were lower, the bias would would be farther from zero.

## Conclusion & Next Steps

Based upon the linear regression analysis above, it is observed that there may be a causal relationship between XX and YY. The hypothesis posed within the introduction is 'failed to be rejected/ rejected.' ....

For future analysis, it is recommended that Covid-19 policy adherence data per county be incorporated into the model to increase the accuracy. While the Govenor of Texas issued detailed protocols or mandates for the state of Texas, the degree to which each county (and thus the individual residents) complied would be useful data to have if such data were to exist.

## References

